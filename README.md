# MediaConfidant - Analytics Pipeline as Code for Data Products

## Project Overview
This project integrates advertising data from various platforms using BigQuery, Dataform, and Looker to provide comprehensive insights into ad performance. This repository contains the code and documentation for an analytics pipeline built for MediaConfidant using Google Cloud Workflows and Pulumi and other Google Cloud services. This pipeline automates data ingestion, transformation, analysis, and reporting to provide actionable insights for MediaConfidant's business. 

![MediaConfidant: Analytics Pipeline as Code on GCP](https://github.com/wrenchchatrepo/mediaconfidant/assets/158282973/2a86eb68-5be5-4714-84c4-571f2e256f82)

### Proposal for a Data Product Using Dataform, Looker, and BigQuery Machine Learning

The Data Product is a result of the Analytics Pipeline: the data model includes a semantic layer and data
transformations both with version control, sophisticated analytics, practical ML, and data integrity. This solution is
intended to be a blueprint for the customer MediaConfidant to build on Google Cloud. Infrastructure and Analytics as
Code means instructions are provided for provisioning the infrastructure, code snippets as examples, and thorough
documentation for every step.

The modern data stack is a collection of tools that work together to help businesses collect, clean, analyze, and
visualize data. Dataform, Looker, and BigQuery create a powerful analytical stack but are only part of the solution.

This document outlines the necessary supporting infrastructure with the following objectives:
+ Improved data insights: BigQuery's analytics engine can be used with Looker to produce more than just data.
+ Improved data quality: Dataform can be used to clean and validate data before it is loaded into BigQuery.
+ Increased data accessibility: Looker provides a user-friendly interface for users to access and explore data.
+ Data integration: Dataform will be used to integrate data from multiple sources into BigQuery.

### Architecture
This project utilizes a modular workflow approach to manage the entire data pipeline. Each workflow
represents a distinct stage of the process, ensuring a clear and organized structure.

### Data Sources
	Google Ads
	Facebook Ads
	Bing Ads
	TikTok Ads
	Google Analytics

## Analytics Engineering
1. Data Ingestion:
+ Data from various sources like BingAds and TikTok Ads is ingested into BigQuery then moved to Cloud Storage.
+ Google Analytics data is exported to BigQuery ML.
2. Data Processing:
+ BigQuery ML processes data from Cloud Storage and other sources.
+ DataForm integrates with GitHub for version control and uses Cloud Functions for automation.
+ SQLX is used within DataForm for data transformations.
3. Data Model:
+ Looker is used for data visualization and reporting.
+ LookML integrates with SQLX to add relational integrity.
+ Spectacles is recommendaed for LookML and content validation.
4. Outputs
+ Dashboards: Generated by Looker for data visualization.
+ Looker Actions: Custom actions integrated into Looker.
+ Looker API: Used for programmatically accessing Looker data.
+ Looker SDK: For integrating Looker with other applications.
+ Cloud Marketplace: For publishing and accessing Looker applications.

## Infrastructure as Code

### Cloud Environment
+ Docker: Containerization for applications.
+ Resource Manager: For managing cloud resources.
+ Cloud APIs: Various APIs provided by Google Cloud.
+ Billing: Managing billing and costs.
+ VPC: Virtual Private Cloud for networking.
+ Firewall: Security and access control.
+ Workflows: Orchestrating complex workflows.
+ Cloud SDK: Tools and libraries for cloud management.
+ Deployment API: Automated deployment of applications.
+ Cloud Build: CI/CD for building and deploying applications.
+ Vertex AI: For machine learning and AI applications.
+ Cloud Logging: Centralized logging for monitoring and troubleshooting.

### Getting Started
To get started with the project, follow these steps:
1. Set up your environment:
+ Ensure you have the required tools installed, such as Docker, Cloud SDK, and other dependencies.
+ Follow the setup instructions in the relevant directories.
2. Deploy the infrastructure:
+ Use Pulumi Go Commands to set up the infrastructure on GCP.
+ Ensure all services are correctly configured and accessible.
3. Run the data pipeline:
+ Use DataForm to execute the data ingestion and transformation processes.
+ Monitor the pipeline using Cloud Logging and Cloud Monitoring.

### Issues
<!-- issueTable -->
| Title                                                                                                  |         Status          | Assignee | Body           |
| :----------------------------------------------------------------------------------------------------- | :---------------------: | :------: | :------------- |
| <a href="https://github.com/wrenchchatrepo/orale_customer/issues/1">Just a test of a github action</a> | :eight_spoked_asterisk: |          | Please ignore. |
<!-- issueTable -->

### Directory Structure
```
/dataform
	/definitions
	standardized_ads_data.sqlx
	combined_metrics.sqlx
	/dataform.json
/bigquery
	google_ads_schema.sql
	facebook_ads_schema.sql
	bing_ads_schema.sql
	tiktok_ads_schema.sql
	google_analytics_schema.sql
/looker
	/views
	standardized_ads_data.view.lkml
	combined_metrics.view.lkml
	logistic_regression_predictions.view.lkml
	arima_plus_forecasts.view.lkml
	/models
	data_product.model.lkml
	/manifest
	manifest.lkml
	/dashboards
	combined_metrics_dashboard.dashboard.lkml
	logistic_regression_predictions_dashboard.dashboard.lkml
	arima_plus_forecasts_dashboard.dashboard.lkml
/scripts
	create_standardized_ads_data_view.py
	create_combined_metrics_view.py
	create_logistic_regression_predictions_view.py
	create_arima_plus_forecasts_view.py
	create_model_file.py
	create_manifest_file.py
	create_combined_metrics_dashboard.py
	create_logistic_regression_predictions_dashboard.py
	create_arima_plus_forecasts_dashboard.py
```

## The provided document is a comprehensive plan for integrating and analyzing advertising data from various platforms using BigQuery, Dataform, and Looker. It covers the following key areas:
1. Metrics Identification:
+ Detailed metrics for Google Analytics, Google Ads, Bing Ads, Facebook Ads, Instagram Ads, and TikTok Business Ads.
+ Combining these metrics to create new metrics like Ad Conversion Rate, Ad ROI, Session Value, Ad Engagement Rate, Bounce Rate per Ad Channel, Cross-Channel Conversion Rate, Average Session Duration per Ad Channel, and Ad Cost per Acquisition (CPA).
2. Google Analytics Export to BigQuery:
+ Steps to set up BigQuery linking and data export.
+ Schema and structure of exported data.
3. Data Integration from Various Platforms:
+ Instructions for setting up data transfers for Google Ads and Facebook Ads using BigQuery Data Transfer Service.
+ API calls for Bing Ads and TikTok Ads, including authentication and fetching ad data.
+ Loading data into BigQuery tables and transforming the data using Dataform SQLX.
4. Estimating Data Volume and Storage:
+ Estimations for the amount of data pulled daily and weekly.
+ Calculations based on the number of campaigns, data points per record, and row sizes.
5. BigQuery Table Schemas:
+ Schemas for raw data tables for each ad platform and Google Analytics.
+ Transformed data tables like standardized_ads_data and combined_metrics.
6. LookML Implementation:
+ View files for standardized_ads_data and combined_metrics.
+ Model file for defining explores and joins.
+ Manifest file for defining the dashboards.
7. Looker Dashboards:
+ Dashboards for combined_metrics, logistic_regression_predictions, and arima_plus_forecasts.
8. Row-Level Security with Looker User Attributes:
+ Using user attributes to securely deliver data to customers through the Looker UI.
9. BigQuery ML Models:
+ Logistic Regression for binary classification and ARIMA_PLUS for time series forecasting.
+ SQL scripts for data preparation, training models, and making predictions.

## Summary of Key Code Sections
### View Files
+ standardized_ads_data.view.lkml: Defines the schema for standardized ads data.
+ combined_metrics.view.lkml: Defines the schema + logistic_regression_predictions.view.lkml: Defines the schema for logistic regression predictions.
+ arima_plus_forecasts.view.lkml: Defines the schema for ARIMA_PLUS forecasts.
### Model File
+ data_product.model.lkml: Includes views and defines explores for data_product_explore.
### Manifest File
+ manifest.lkml: Defines the project, models, and dashboards.
### Dashboards
+ combined_metrics_dashboard.dashboard.lkml: Dashboard for combined metrics.
+ logistic_regression_predictions_dashboard.dashboard.lkml: Dashboard for logistic regression predictions.
+ arima_plus_forecasts_dashboard.dashboard.lkml: Dashboard for ARIMA_PLUS forecasts.
### Metrics by Data Source
| Metric                   | Google Analytics | Google Ads | Bing Ads | Facebook Ads | Instagram Ads | TikTok Business Ads |
|--------------------------|------------------|------------|----------|--------------|---------------|---------------------|
| Users                    | X                |            |          |              |               |                     |
| Sessions                 | X                |            |          |              |               |                     |
| Bounce Rate              | X                |            |          |              |               |                     |
| Average Session Duration | X                |            |          |              |               |                     |
| Pageviews                | X                |            |          |              |               |                     |
| Clicks                   |                  | X          | X        | X            | X             |                     |
| Impressions              |                  | X          | X        | X            | X             | X                   |
| CTR (Click-Through Rate) |                  | X          | X        | X            | X             | X                   |
| CPC (Cost Per Click)     |                  | X          | X        | X            | X             |                     |
| Conversions              |                  | X          | X        |              |               | X                   |
| Reach                    |                  |            |          | X            | X             |                     |
| Engagement               |                  |            |          | X            | X             |                     |
| Video Views              |                  |            |          |              |               | X                   |
| Engagement Rate          |                  |            |          |              |               | X                   |
| Conversion Rate          |                  |            |          |              |               | X                   |
### Google Analytics
1. Users. The number of unique visitors to your website.
2. Sessions. A group of interactions that take place on your website within a given time frame.
3. Bounce Rate. The percentage of single-page sessions where there was no interaction with the page.
4. Average Session Duration. The average length of a session on your website.
5. Pageviews. The total number of pages viewed. Repeated views of a single page are counted.
### Google Ads
1. Clicks. The number of times users clicked on your ad.
2. Impressions. The number of times your ad was shown on a search result page or other site on the Google Network.
3. CTR (Click-Through Rate). The ratio of users who click on your ad to the number of total users who view your ad.
4. CPC (Cost Per Click). The average cost you pay for each click on your ad.
5. Conversions. The number of times users completed a desired action (e.g., purchase, sign-up) after clicking on your ad.
### Bing Ads
1. Clicks. The number of clicks your ads receive.
2. Impressions. The number of times your ads are displayed on Bing Network search results.
3. CTR (Click-Through Rate). The percentage of people who clicked your ad after seeing it.
4. CPC (Cost Per Click). The amount you pay for each click on your ad.
5. Conversions. Actions counted when someone interacts with your ad (e.g., clicks it) and then takes an action you’ve defined as valuable to your business.
### Meta Ads (Facebook, Instagram)
1. Reach. The number of unique users who have seen your ad.
2. Impressions. The number of times your ads were on screen.
3. Engagement. The total number of actions (likes, comments, shares) people take involving your ads.
4. CTR (Click-Through Rate). The ratio of users who click on your ad to the number of total users who view your ad.
5. CPC (Cost Per Click). The amount you pay for each click on your ad.
### TikTok Business Ads
1. Video Views. The number of times your video ad was viewed.
2. Impressions. The number of times your ad was shown on TikTok.
3. CTR (Click-Through Rate). The percentage of people who clicked your ad after seeing it.
4. Engagement Rate. The ratio of engagements (likes, comments, shares) to impressions.
5. Conversion Rate. The percentage of users who completed a desired action (e.g., sign-up, purchase) after interacting with your ad.
### Combined Metrics
Combining metrics from Google Analytics with those from advertising platforms like Google Ads, Bing Ads, Facebook Ads, Instagram Ads, and TikTok Business Ads can provide deeper insights into the effectiveness of ad campaigns and their impact on website performance. Here are a few new metrics, their calculations, and the insights they could provide:

1. Ad Conversion Rate
+ Calculation:
\text{Ad Conversion Rate} = \frac{\text{Conversions (Ad Platform)}}{\text{Clicks (Ad Platform)}} \times 100
+ This metric shows the effectiveness of an ad in driving users to complete a desired action (e.g., purchase, sign-up). A high conversion rate indicates that the ad is highly relevant and persuasive.

2. Ad ROI (Return on Investment)
+ Calculation:
\text{Ad ROI} = \frac{\text{Revenue (Google Analytics)}}{\text{Cost (Ad Platform)}} \times 100
+ This metric measures the profitability of the ad campaign. A high ROI indicates that the campaign is generating significant revenue relative to its cost.

3. Session Value
+ Calculation:
\text{Session Value} = \frac{\text{Revenue (Google Analytics)}}{\text{Sessions (Google Analytics)}}
+ This metric provides an average value of each session on the website. It helps in understanding how much revenue each visit brings, which can guide budget allocation for ad campaigns.

4. Ad Engagement Rate
+ Calculation:
\text{Ad Engagement Rate} = \frac{\text{Engagements (Ad Platform)}}{\text{Impressions (Ad Platform)}} \times 100
+ This metric shows how engaging the ad is to the audience. A high engagement rate indicates that the ad content resonates well with the viewers.

5. Bounce Rate per Ad Channel
+ Calculation:
\text{Bounce Rate per Ad Channel} = \frac{\text{Single-Page Sessions (Google Analytics)}}{\text{Sessions (Google Analytics)}} \times 100 \quad \text{(for traffic from each ad channel)}
+ This metric helps in understanding the quality of traffic from each ad channel. A high bounce rate indicates that users are not finding what they expected on the landing page.

6. Cross-Channel Conversion Rate
+ Calculation:
\text{Cross-Channel Conversion Rate} = \frac{\text{Conversions (Google Analytics)}}{\text{Total Clicks from All Ad Platforms}} \times 100
+ This metric provides an overall view of how effective all ad campaigns combined are in driving conversions. It helps in assessing the combined impact of multi-channel ad strategies.

7. Average Session Duration per Ad Channel
+ Calculation:
\text{Average Session Duration per Ad Channel} = \frac{\text{Total Session Duration (Google Analytics)}}{\text{Sessions (Google Analytics)}} \quad \text{(for traffic from each ad channel)}
+ This metric helps in understanding how engaged users from different ad channels are. Longer session durations indicate higher engagement levels.

8. Ad Cost per Acquisition (CPA)
+ Calculation:
\text{Ad CPA} = \frac{\text{Cost (Ad Platform)}}{\text{Conversions (Google Analytics)}}
+ This metric shows the cost-effectiveness of ad campaigns in acquiring customers. A lower CPA indicates a more cost-efficient campaign.

### Example Names and Insights for New Metrics:
1. Ad Conversion Rate: Measures the efficiency of ad campaigns in converting clicks to actions.
2. Ad ROI: Assesses the profitability of ad campaigns.
3. Session Value: Indicates the average revenue per session.
4. Ad Engagement Rate: Evaluates the level of engagement generated by ads.
5. Bounce Rate per Ad Channel: Analyzes the quality of traffic from different ad channels.
6. Cross-Channel Conversion Rate: Provides a holistic view of multi-channel ad effectiveness.
7. Average Session Duration per Ad Channel: Understands user engagement from various ad sources.
8. Ad Cost per Acquisition (CPA): Determines the cost efficiency in acquiring new customers.

## Setting Up Export to BigQuery

Google Analytics’ Export to BigQuery feature allows you to export raw event data from Google Analytics to Google BigQuery, enabling deeper and more flexible analysis using SQL queries. Here’s how it works:
1. Enable BigQuery Linking:
+ Go to the Google Analytics Admin section.
+ In the “Property” column, click “BigQuery Linking.”
+ Click “+ Link” to create a new link between Google Analytics and BigQuery.
+ Follow the setup wizard, selecting the BigQuery project and dataset where you want the data to be exported.
2. Configure Data Export:
+ Choose the data streams (web and/or app) that you want to export.
+ Set the export frequency (daily or streaming export).
+ Review and complete the setup.

When the data is exported, it is stored in a specific structure within BigQuery:
+ Dataset: The data is stored in a BigQuery dataset.
+ Tables: The dataset contains tables for each day of data. For example, a table for data collected on June 1st, 2024, would be named events_20240601.

The schema of the exported data includes the following fields:
1. event_date: The date on which the event occurred.
2. event_timestamp: The timestamp of the event.
3. event_name: The name of the event.
4. user_id: The unique identifier for the user.
5. user_properties: Custom properties associated with the user.
6. event_params: Parameters associated with the event.
7. geo: Geographical information about the user.
8. app_info: Information about the app where the event occurred.
9. traffic_source: Information about the traffic source.

Once the data is in BigQuery, you can use SQL queries to analyze it. For example:
```
-- Example query to get the number of users per event type
SELECT
  event_name,
  COUNT(DISTINCT user_id) AS user_count
FROM
  `project_id.dataset_id.events_*`
WHERE
  _TABLE_SUFFIX BETWEEN '20240601' AND '20240630'
GROUP BY
  event_name
ORDER BY
  user_count DESC;
```

### Benefits of Exporting to BigQuery
+ Advanced Analysis: Perform complex queries and analysis that are not possible in the Google Analytics interface.
+ Integration: Integrate Google Analytics data with other datasets in BigQuery for a comprehensive view of your data.
+ Custom Reporting: Create custom reports and dashboards using tools like Google Data Studio, directly connected to BigQuery.

### Considerations
+ Cost: BigQuery charges for data storage and queries, so it’s important to monitor usage and costs.
+ Data Freshness: Depending on your configuration, there may be a delay between data 

### Integrating the Data
To integrate data from Google Ads, Facebook Ads, TikTok, and Bing Ads with Google Analytics data in BigQuery, you’ll need to use a combination of data transfers, API integrations, and data transformations. Here’s a step-by-step guide on how to achieve this integration and perform necessary transformations using Dataform:

### Step-by-Step Guide
1. Setting Up Data Transfers and API Integrations for Google Ads and Facebook Ads
+ Google Ads:
+ Use the BigQuery Data Transfer Service to set up a transfer from Google Ads.
+ In the Google Cloud Console, navigate to BigQuery and select “Transfers.”
+ Create a new transfer and select “Google Ads” as the data source.
+ Follow the setup wizard to authorize and configure the transfer.
+ Facebook Ads:
+ Similar to Google Ads, use the BigQuery Data Transfer Service.
+ Select “Facebook Ads” as the data source and follow the setup wizard.
2. TikTok and Bing Ads API Integration:
+ TikTok Ads:
+ Use the TikTok for Business API to fetch ad data.
+ Implement a scheduled Cloud Function or a Cloud Run service to call the API and store the data in BigQuery.
+ Bing Ads:
+ Use the Bing Ads API to fetch ad data.
+ Similar to TikTok, use a scheduled Cloud Function or Cloud Run to call the API and load data into BigQuery.

Bing Ads API Calls

1. Authentication:
+ Use OAuth2 to get an access token.
+ Example using Python and requests library:
```
import requests

client_id = 'YOUR_CLIENT_ID'
client_secret = 'YOUR_CLIENT_SECRET'
refresh_token = 'YOUR_REFRESH_TOKEN'

token_url = 'https://login.microsoftonline.com/common/oauth2/v2.0/token'
headers = {'Content-Type': 'application/x-www-form-urlencoded'}
data = {
    'client_id': client_id,
    'client_secret': client_secret,
    'refresh_token': refresh_token,
    'grant_type': 'refresh_token',
    'scope': 'https://ads.microsoft.com/.default'
}

response = requests.post(token_url, headers=headers, data=data)
access_token = response.json().get('access_token')
```

2.	Fetching Ad Data:
+ Use the Reporting API to get performance data.
+ Example for fetching a report:
```
report_request = {
    "ReportRequest": {
        "ReportName": "AdPerformanceReport",
        "Format": "Csv",
        "ReportType": "AdPerformanceReport",
        "ReturnOnlyCompleteData": False,
        "Aggregation": "Daily",
        "Scope": {
            "AccountIds": [YOUR_ACCOUNT_ID]
        },
        "Time": {
            "CustomDateRangeStart": {
                "Year": 2023,
                "Month": 1,
                "Day": 1
            },
            "CustomDateRangeEnd": {
                "Year": 2023,
                "Month": 1,
                "Day": 31
            }
        },
        "Columns": [
            "TimePeriod",
            "AccountId",
            "CampaignId",
            "AdId",
            "Impressions",
            "Clicks",
            "Spend",
            "Conversions"
        ]
    }
}

headers = {
    'Authorization': f'Bearer {access_token}',
    'Content-Type': 'application/json'
}

report_url = 'https://api.bingads.microsoft.com/v13/Reporting/SubmitGenerateReport'
response = requests.post(report_url, headers=headers, json=report_request)
report_id = response.json().get('ReportRequestId')

# Check report status and download once ready
```
TikTok Ads API Calls

1. Authentication:
+ Use OAuth2 to get an access token.
+ Example using Python and requests library:
```
import requests

client_key = 'YOUR_CLIENT_KEY'
client_secret = 'YOUR_CLIENT_SECRET'
auth_code = 'YOUR_AUTH_CODE'

token_url = 'https://business-api.tiktok.com/open_api/v1.2/oauth2/access_token/'
headers = {'Content-Type': 'application/json'}
data = {
    'app_id': client_key,
    'secret': client_secret,
    'auth_code': auth_code,
    'grant_type': 'authorization_code'
}

response = requests.post(token_url, headers=headers, json=data)
access_token = response.json().get('data').get('access_token')
```
2.	Fetching Ad Data:
+ Use the Reporting API to get performance data.
+ Example for fetching a report:
```
report_request = {
    "advertiser_id": "YOUR_ADVERTISER_ID",
    "report_type": "BASIC",
    "dimensions": ["ad_id", "campaign_id", "date"],
    "metrics": ["impressions", "clicks", "spend", "conversions"],
    "start_date": "2023-01-01",
    "end_date": "2023-01-31",
    "page": 1,
    "page_size": 1000
}

headers = {
    'Access-Token': access_token,
    'Content-Type': 'application/json'
}

report_url = 'https://business-api.tiktok.com/open_api/v1.2/reports/integrated/get/'
response = requests.post(report_url, headers=headers, json=report_request)
report_data = response.json().get('data')
```

2. Loading Data into BigQuery
+ Ensure each data source (Google Ads, Facebook Ads, TikTok Ads, Bing Ads) is loaded into separate tables within a BigQuery dataset. For example:
+ google_ads_data
+ facebook_ads_data
+ tiktok_ads_data
+ bing_ads_data

Integrating Data with BigQuery

1. Load Data into BigQuery:
+ Use Google Cloud client libraries to load the fetched data into BigQuery.
+ Example using Python:
```
from google.cloud import bigquery

client = bigquery.Client()

dataset_id = 'your_project.your_dataset'
table_id = f'{dataset_id}.bing_ads_data'
job_config = bigquery.LoadJobConfig(
    schema=[
        bigquery.SchemaField("ad_id", "STRING"),
        bigquery.SchemaField("campaign_id", "STRING"),
        bigquery.SchemaField("date", "DATE"),
        bigquery.SchemaField("impressions", "INTEGER"),
        bigquery.SchemaField("clicks", "INTEGER"),
        bigquery.SchemaField("spend", "FLOAT"),
        bigquery.SchemaField("conversions", "INTEGER"),
    ],
    skip_leading_rows=1,
    source_format=bigquery.SourceFormat.CSV,
)

uri = "gs://your_bucket/bing_ads_report.csv"
load_job = client.load_table_from_uri(
    uri, table_id, job_config=job_config
)

load_job.result()
```
2. Transform Data Using Dataform:
+ Set up Dataform to perform transformations and combine the data with Google Analytics data.
```
config {
  type: "table",
  description: "Combined metrics with Google Analytics data"
}

select
  ads.ad_id,
  ads.campaign_id,
  ads.platform,
  ads.impressions,
  ads.clicks,
  ads.conversions,
  ads.spend as cost,
  ga.sessions,
  ga.bounce_rate,
  ga.avg_session_duration,
  ga.pageviews,
  ads.spend / ads.conversions as cpa,
  ga.revenue
from ${ref("standardized_ads_data")} as ads
left join ${ref("google_analytics_data")} as ga
on ads.timestamp = ga.date and ads.campaign_id = ga.campaign_id
```

3. Transforming Data Using Dataform
+ Use Dataform to define transformations and create a unified view of your ad data.

Example Dataform Project Structure
+ project.sqlx
+ Contains the main transformations and definitions.

Example SQLX Transformations
1. Create Unified Ad Table:
```
config {
  type: "table",
  description: "Unified ad data from multiple sources"
}
select * from ${ref("google_ads_data")}
union all
select * from ${ref("facebook_ads_data")}
union all
select * from ${ref("tiktok_ads_data")}
union all
select * from ${ref("bing_ads_data")}
```
2. Transformations to Align Data:
+ Ensure columns from different data sources are named consistently.
+ Example transformation to standardize column names:
```
config {
  type: "table",
  description: "Standardized ad data"
}

select
  ad_id,
  campaign_id,
  source as platform,
  cast(impressions as int64) as impressions,
  cast(clicks as int64) as clicks,
  cast(conversions as int64) as conversions,
  cast(cost as float64) as cost,
  parse_timestamp("%Y-%m-%dT%H:%M:%S%z", timestamp) as timestamp
from ${ref("unified_ads_data")}
```
3.	Join with Google Analytics Data:
```
config {
  type: "table",
  description: "Combined metrics with Google Analytics data"
}
select
  ads.ad_id,
  ads.campaign_id,
  ads.platform,
  ads.impressions,
  ads.clicks,
  ads.conversions,
  ads.cost,
  ga.sessions,
  ga.bounce_rate,
  ga.avg_session_duration,
  ga.pageviews,
  ads.cost / ads.conversions as cpa,
  ga.revenue
from ${ref("standardized_ads_data")} as ads
left join ${ref("google_analytics_data")} as ga
on ads.timestamp = ga.date and ads.campaign_id = ga.campaign_id
```
The amount of data pulled daily and the intervals can vary based on several factors, including the volume of ad activity, the number of campaigns, and the specific requirements of your business. Here’s a general guideline for each vendor:

Google Ads and Facebook Ads (via BigQuery Data Transfer Service)
+ Data Volume: The volume of data can range from a few megabytes to several gigabytes per day, depending on the number of ad impressions, clicks, and conversions.
+ Interval: The data transfer service typically pulls data once daily. This is usually set up to run during off-peak hours to minimize any impact on performance.

Bing Ads and TikTok Ads (via API)
For both Bing Ads and TikTok Ads, you will need to set up custom scripts or functions to pull data. The volume and frequency will depend on your ad activity and the API rate limits.

Bing Ads
+ Data Volume: Similar to Google Ads and Facebook Ads, it can range from megabytes to gigabytes per day.
+ Interval: You can schedule data pulls at intervals that balance the need for up-to-date data with API rate limits and performance considerations. Common intervals are:
+ Daily: Pulling data once every 24 hours, typically during off-peak hours.
+ Hourly: For more real-time insights, you can pull data every hour, but this increases the load on your API quota.

TikTok Ads
+ Data Volume: Similar to other ad platforms, expect data volume to range from megabytes to gigabytes per day.
+ Interval: Similar to Bing Ads:
+ Daily: Once every 24 hours is a common schedule.
+ Hourly: If real-time insights are critical, you can schedule more frequent pulls.
